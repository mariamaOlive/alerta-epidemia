///////////////////Carregando Dados//////////////////////////////
//Colocar csvs nessa pastas
C:\Users\mcso\.Neo4jDesktop\relate-data\dbmss\dbms-69782ce3-52fa-480a-8249-0bafb6cbe2a3\import

LOAD CSV WITH HEADERS FROM "file:///estado.csv" AS row
MERGE (:Estado {
cod_uf: toInteger(row.cod_uf), 
nome: row.nome_uf, 
uf: row.uf,
populacao: toInteger(row.populacao_2021),
densidade_pop: toFloat(row.densidade_2021)})


// WITH "https://github.com/mariamaOlive/alerta-epidemia/tree/main/data/integrado/" AS base
// WITH base + "municipio.csv" AS uri
LOAD CSV WITH HEADERS FROM "file:///municipio.csv" AS row  with row where row.longitude is not null
MERGE (:Cidade {cod_mun: toInteger(row.cod_mun), 
nome: row.nome_mun, 
latitude: toFloat(row.latitude), 
longitude: toFloat(row.longitude), 
populacao: toInteger(row.populacao_2021),
densidade_pop: toFloat(row.densidade_2021)})

LOAD CSV WITH HEADERS FROM "file:///municipio.csv" AS row  with row where row.densidade_2021 is not null
MERGE (:Municipio {
cod_mun: toInteger(row.cod_mun), 
nome: row.nome_mun, 
latitude: toFloat(row.latitude), 
longitude: toFloat(row.longitude), 
populacao: toInteger(row.populacao_2021),
densidade_pop: toFloat(row.densidade_2021),
cod_uf:toInteger(row.cod_uf),
cod_reg_saude:toInteger(row.cod_reg_saude)})

//Criando nó des arranjo
LOAD CSV WITH HEADERS FROM "file:///arranjo.csv" AS row  
MERGE (:Arranjo_Populacional {
cod_mun: toInteger(row.cod_arranjo), 
nome: row.nome_arranjo})


//Criando nó de Regiao de Saúde
LOAD CSV WITH HEADERS FROM "file:///regiao_saude.csv" AS row  
MERGE (:Regiao_Saude {
cod_reg_saude: toInteger(row.cod_reg_saude), 
nome: row.nome_reg_saude, 
latitude: toFloat(row.latitude), 
longitude: toFloat(row.longitude)})

//Criando nó de Rede Sentinela
LOAD CSV WITH HEADERS FROM "file:///servico_sentinela.csv" AS row  
MERGE (:Rede_Sentinela {
cod_mun: toInteger(row.cod_mun), 
nome_servico: row.nome_serv})

LOAD CSV WITH HEADERS FROM "file:///hierarquia.csv" AS row  
MERGE (:Hierarquia {
hierarquia: row.hierarquia, 
nome_hierarquia: row.nome_hierarquia})

//Updating
LOAD CSV WITH HEADERS FROM "file:///cidades_regic.csv" AS row  
MERGE (c:Cidade {cod_mun: toInteger(row.cod_mun)})
ON MATCH SET c.PIB= toInteger(row.PIB), c.hierarquia= row.hierarquia, 
c.nome_hierarquia= row.nome_hierarquia, c.indice_atracao= toFloat(row.indice_atracao),
c.ia_saude_bm= toFloat(row.ia_saude_bm), c.ia_saude_a= toFloat(row.ia_saude_a),
c.ia_aeroporto= toFloat(row.ia_aeroporto), c.ia_transporte= toFloat(row.ia_transporte),
c.num_leitos= toFloat(row.num_leitos)
//ON MATCH SET n.TotalRevenue = csvLine[2] --> Faz um update
//ON CREATE --> Cria o nó caso precise
LOAD CSV WITH HEADERS FROM "file:///cidades_regic.csv" AS row  
MERGE (c:Cidade {cod_mun: toInteger(row.cod_mun)})
ON MATCH SET c.hierarquia= row.hierarquia

//Adicionando dados relativos a propagacao da doenca
LOAD CSV WITH HEADERS FROM "file:///spreaders_s15.csv" AS row  
MERGE (c:Cidade {cod_mun: toInteger(row.cod_mun)})
ON MATCH SET c.total_cidade= toFloat(row.cidade),
c.total_pais= toFloat(row.total),
c.total_outras_cidades = toFloat(row.espalhamento)

MATCH (c:Cidade)
REMOVE c.total_cidade,c.total_pais, c.total_outras_cidades
RETURN c.total_cidade

LOAD CSV WITH HEADERS FROM "file:///cidades_regic.csv" AS row  
MATCH (c:Cidade {cod_mun: toInteger(row.cod_mun)})
SET c.hierarquia= row.hierarquia

LOAD CSV WITH HEADERS FROM "file:///cidades_regic.csv" AS row  
MATCH (c:Cidade {cod_arranjo: toInteger(row.cod_mun)})
SET c.hierarquia= row.hierarquia

//Adicionando propriedades no arranjo populacional
LOAD CSV WITH HEADERS FROM "file:///arr_mun.csv" AS row  
MATCH (a:Arranjo_Populacional {cod_mun: toInteger(row.cod_cidade)})
SET a.populacao= toInteger(row.populacao_2021),
a.latitude = toFloat(row.latitude),
a.longitude = toFloat(row.longitude),
a.densidade = toFloat(row.densidade_2021)


//And this query imports relationships:
// WITH "https://github.com/mariamaOlive/alerta-epidemia/tree/main/data/calculado/" AS base
// WITH base + "fluxo_prob.csv" AS uri
LOAD CSV WITH HEADERS FROM "file:///fluxo_prob.csv" AS row 
MATCH (origem:Cidade {cod_mun: toInteger(row.cod_origem)})
MATCH (destino:Cidade {cod_mun: toInteger(row.cod_destino)})
MERGE (origem)-[r:TEM_CONEXAO{ fluxo_geral: toFloat(row.prob_geral), fluxo_aereo: toFloat(row.prob_aereo), fluxo_rodo: toFloat(row.prob_rodo) }]->(destino)

LOAD CSV WITH HEADERS FROM "file:///fluxo_prob_qtd.csv" AS row 
MATCH (origem:Cidade {cod_mun: toInteger(row.cod_origem)})
MATCH (destino:Cidade {cod_mun: toInteger(row.cod_destino)})
MERGE (origem)-[r:FLUXO_TRANSPORTE{ 
  fluxo_geral: toFloat(row.prob_geral), 
  fluxo_aereo: toFloat(row.prob_aereo), 
  fluxo_rodo: toFloat(row.prob_rodo),
  total_pessoas:toInteger(row.total_pessoas) }]->(destino)

//Adicionar fluxo com Arranjo
LOAD CSV WITH HEADERS FROM "file:///arr_calculo_qtd_fluxo.csv" AS row 
MATCH (origem:Cidade {cod_mun: toInteger(row.cod_origem)})
MATCH (destino:Cidade {cod_mun: toInteger(row.cod_destino)})
MERGE (origem)-[r:FLUXO_TRANSPORTE{ 
  fluxo_geral: toFloat(row.prob_total), 
  fluxo_aereo: toFloat(row.prob_aereo), 
  fluxo_rodo: toFloat(row.prob_rodov),
  total_pessoas:toInteger(row.passageiros_total) }]->(destino)


//Criando relacionamento arranjo e municipio
LOAD CSV WITH HEADERS FROM "file:///arranjo_com_mun.csv" AS row 
MATCH (municipio:Municipio {cod_mun: toInteger(row.cod_mun)})
MATCH (arr:Arranjo_Populacional {cod_arranjo: toInteger(row.cod_arranjo)})
MERGE (municipio)-[r:PERTENCE_ARR]->(arr) 


//Criando o relacionamento de fluxo de saude
LOAD CSV WITH HEADERS FROM "file:///fluxo_saude.csv" AS row 
MATCH (origem:Municipio {cod_mun: toInteger(row.cod_origem)})
MATCH (destino:Municipio {cod_mun: toInteger(row.cod_destino)})
MERGE (origem)-[r:FLUXO_SAUDE]->(destino) 
ON CREATE SET r.saude_baixa_media = toFloat(row.saude_baixa_media), r.saude_alta = toFloat(row.saude_alta)
ON MATCH SET r.saude_baixa_media = toFloat(row.saude_baixa_media), r.saude_alta = toFloat(row.saude_alta)

//Updating relationship - add inverse probability
MATCH (c_origem:Cidade)-[r:FLUXO_TRANSPORTE]->(c_destino:Cidade)
WHERE r.fluxo_geral>0
SET r.fluxo_invertido = 1 - r.fluxo_geral
RETURN count(r)


//Updating node
MERGE (c:Cidade {cod_mun: toInteger(row.cod_mun)})
ON MATCH SET c.PIB= toInteger(row.PIB), c.hierarquia= row.hierarquia, 
c.nome_hierarquia= row.nome_hierarquia, c.indice_atracao= toFloat(row.indice_atracao),
c.ia_saude_bm= toFloat(row.ia_saude_bm), c.ia_saude_a= toFloat(row.ia_saude_a),
c.ia_aeroporto= toFloat(row.ia_aeroporto), c.ia_transporte= toFloat(row.ia_transporte),
c.num_leitos= toFloat(row.num_leitos)


//Criando relationship de estado com cidade
MATCH (c:Municipio), (e:Estado) 
WHERE c.cod_uf = e.cod_uf 
CREATE (c)-[r:PERTENCE_ESTADO]->(e) 
RETURN c,e 

//Criando relationship de municipio com regiao de saude
MATCH (c:Municipio), (rs:Regiao_Saude) 
WHERE c.cod_reg_saude = rs.cod_reg_saude 
CREATE (c)-[r:PERTENCE_REGIAO]->(rs) 
RETURN c,rs 

//Criando relationship de municipio com rede sentinela
MATCH (c:Municipio)
WITH c
MATCH (rs:Rede_Sentinela) 
WHERE c.cod_mun = rs.cod_mun
CREATE (rs)-[r:ESTA_LOCALIZADA]->(c)
RETURN c,rs 

//A hierarquia é dada por cidade = arranjo + municipio
MATCH (c:Cidade) 
WITH c
MATCH (h:Hierarquia) 
WHERE c.hierarquia = h.hierarquia
CREATE (c)-[r:CLASSIFICADA]->(h)
RETURN c,h

//Adicionando o label de Cidade para arranjos e municipios
LOAD CSV WITH HEADERS FROM "file:///arr_mun_sem_arr.csv" AS row 
MATCH (mun:Municipio {cod_mun: toInteger(row.cod_cidade)})
SET mun:Cidade

MATCH (arr: Arranjo_Populacional)
SET arr:Cidade

//Removendo propriedades
MATCH (c:Cidade)
REMOVE c.cod_reg_saude, c.cod_uf, c.hierarquia

MATCH (r:Rede_Sentinela)
REMOVE r.cod_mun

MATCH (c)
WHERE c:Cidade AND c:Arranjo_Populacional
RETURN count(c)

MATCH (c:Cidade)
REMOVE c:Cidade

MATCH ()-[r:FLUXO_TRANSPORTE]-() 
DELETE r


////////////////////Algoritmos de Centralidade////////////////////////

//Closeness Centrality

CALL gds.graph.project('myGraph', 'Cidade', 'FLUXO')

CALL gds.beta.closeness.stream('myGraph')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).cod_mun AS id, gds.util.asNode(nodeId).nome AS nome, score
ORDER BY score DESC

//Escrevendo
CALL gds.beta.closeness.write('myGraph', { writeProperty: 'closeness' })
YIELD centralityDistribution, nodePropertiesWritten
RETURN centralityDistribution.min AS minimumScore, centralityDistribution.mean AS meanScore, nodePropertiesWritten

//Betweenness Centrality
CALL gds.betweenness.stream('myGraph')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).cod_mun AS id, gds.util.asNode(nodeId).nome AS nome, score
ORDER BY score DESC

//Escrever
CALL gds.betweenness.write('myGraph', { writeProperty: 'betweenness' })
YIELD centralityDistribution, nodePropertiesWritten
RETURN centralityDistribution.min AS minimumScore, centralityDistribution.mean AS meanScore, nodePropertiesWritten

//Page Rank
CALL gds.graph.project(
  'myGraph_peso',
  'Cidade',
  'FLUXO',
  {
    relationshipProperties: 'probabilidade'
  }
)

CALL gds.pageRank.write.estimate('myGraph', {
  writeProperty: 'pageRank',
  maxIterations: 20,
  dampingFactor: 0.85
})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory

CALL gds.pageRank.stream('myGraph_peso')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).nome AS nome, score
ORDER BY score DESC, nome ASC

///Com peso
CALL gds.pageRank.stream('myGraph_peso', {
  maxIterations: 20,
  dampingFactor: 0.85,
  relationshipWeightProperty: 'probabilidade'
})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).nome AS nome, score
ORDER BY score DESC, nome ASC

//Escrevendo
CALL gds.pageRank.write('myGraph_peso', {
  maxIterations: 20,
  dampingFactor: 0.85,
  relationshipWeightProperty: 'probabilidade',
  writeProperty: 'pagerank'
})
YIELD nodePropertiesWritten, ranIterations

//Article to Rank
CALL gds.articleRank.write.estimate('myGraph', {
  writeProperty: 'centrality',
  maxIterations: 20
})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory

CALL gds.articleRank.stream('myGraph')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).nome AS nome, score
ORDER BY score DESC, nome ASC


//Eigenvector Centrality
CALL gds.eigenvector.stream('myGraph_peso')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).nome AS nome, score
ORDER BY score DESC, nome ASC


CALL gds.eigenvector.write('myGraph', {
  maxIterations: 20,
  writeProperty: 'centrality'
})
YIELD nodePropertiesWritten, ranIterations

//Escrever
CALL gds.eigenvector.write('myGraph_peso', {
  maxIterations: 20,
  writeProperty: 'eigenvector'
})
YIELD nodePropertiesWritten, ranIterations


//Degree Centrality
CALL gds.graph.project(
  'myGraph_centrality',
  'Cidade',
  {
    FLUXO: {
      orientation: 'REVERSE',
      properties: ['probabilidade']
    }
  }
)

CALL gds.degree.stream('myGraph_centrality')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).nome AS nome, score AS conexoes
ORDER BY conexoes DESC, nome DESC

//Escrever
CALL gds.degree.write('myGraph', { writeProperty: 'degree' })
YIELD centralityDistribution, nodePropertiesWritten
RETURN centralityDistribution.min AS minimumScore, centralityDistribution.mean AS meanScore, nodePropertiesWritten


//Harmonic Centrality
CALL gds.alpha.closeness.harmonic.stream('myGraph', {})
YIELD nodeId, centrality
RETURN gds.util.asNode(nodeId).nome AS nome, centrality
ORDER BY centrality DESC

//HITS
CALL gds.alpha.hits.stream('myGraph', {hitsIterations: 20})
YIELD nodeId, values
RETURN gds.util.asNode(nodeId).nome AS nome, values.auth AS auth, values.hub as hub
ORDER BY auth DESC

////////////////////Comandos básicos////////////////////////
MATCH (cidade)  
WHERE cidade.cod_mun = 2611606 AND 
RETURN cidade

//Query
MATCH (n)
WHERE n.cod_mun = 2603454
RETURN n
///2611606 --> Recife

MATCH (c1)-[r]-(c2)
WHERE c1.cod_mun = 1302603 AND  c2.cod_mun = 1200203
RETURN c1, c2

MATCH (c)-[r]->(c) WHERE c.cod_mun = 2304400 RETURN COUNT(r)

MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
AND r.probabilidade > 0.015
RETURN c1,c2

MAX


MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
AND c2.pagerank > 13
RETURN c1, c2 

//Calculando valor e salvando
MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
WITH c1, r, c2
SET c2.salvador = c2.closeness*.1 + r.probabilidade*.9
RETURN count(r)


//Calculo
MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408"  
WITH c1, r, c2
RETURN  c2.closeness*.1 + r.probabilidade*.9 



MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
AND c2.salvador > 0.1
RETURN c1, c2 

MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
RETURN c2.nome AS nome, c2.salvador AS salvador
ORDER BY salvador DESC


MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
RETURN c2.nome AS nome, c2.salvador AS salvador
ORDER BY salvador DESC


//CODIGO RETORNAR NOS
MATCH (c1)-[r]->(c2)
WHERE c1.cod_mun = "2927408" 
RETURN c2, c2.salvador AS salvador
ORDER BY salvador DESC LIMIT 10

//Deletar tudo
MATCH (n) DELETE n;

MATCH (n)
DETACH DELETE n

//Remover propriedade de um relatioship
MATCH (c1)-[r]->(c2)
REMOVE r.saude_baixa_media, r.saude_alta


//Cast
match (:Cidade)-[r]->(:Cidade)
where r.probabilidade = toString(r.probabilidade) // make sure we only work string ratings
set r.probabilidade = toFloat(r.probabilidade)
return count(r)


//Consultas feitas no app
MATCH (c1)-[r]->(c2) 
WHERE c1.cod_mun =  2603454
RETURN c2.cod_mun AS cod_mun, c2.nome AS nome, 
r.fluxo_geral AS fluxo_geral, r.fluxo_aereo AS fluxo_aereo, r.fluxo_rodo AS fluxo_rodo, 
r.saude_alta AS saude_alta, r.saude_baixa_media AS saude_baixa_media, 
c2.latitude AS latitude, c2.longitude AS longitude


//Fluxo de regiao de saude (Saude)
MATCH (rs:Regiao_Saude)<-[r:PERTENCE]-(c:Cidade)
WHERE rs.cod_reg_saude = 26006
WITH collect(c) AS cs, sum(c.populacao) AS rs_pop
MATCH (c_ori:Cidade)-[f:FLUXO_SAUDE]->(c_dest:Cidade)-[p:PERTENCE]->(rs_dest:Regiao_Saude)
WHERE c_ori IN cs AND NOT c_dest IN cs 
WITH rs_dest.cod_reg_saude AS cod_regiao, rs_dest.nome AS nome, rs_dest.latitude AS latitude, rs_dest.longitude AS longitude
, collect([c_ori.populacao,f.saude_baixa_media,f.saude_alta]) AS cl, rs_pop AS rs_pop
WITH cod_regiao AS cod_regiao, nome AS nome,latitude AS latitude, longitude AS longitude, 
reduce(res = [0,0] , array IN cl | [res[0] + (array[0]*array[1]), res[1] + (array[0]*array[2])]) AS res, rs_pop AS rs_pop
RETURN cod_regiao, nome, latitude, longitude, res[0]/rs_pop AS saude_baixa_media, res[1]/rs_pop AS saude_alta

//Fluxo de regiao de saude (Transporte)
MATCH (rs:Regiao_Saude)<-[r:PERTENCE]-(c:Cidade)
WHERE rs.cod_reg_saude = 26006
WITH collect(c) AS cs, sum(c.populacao) AS rs_pop
MATCH (c_ori:Cidade)-[f:FLUXO_TRANSPORTE]->(c_dest:Cidade)-[p:PERTENCE]->(rs_dest:Regiao_Saude)
WHERE c_ori IN cs AND NOT c_dest IN cs 
WITH rs_dest.cod_reg_saude AS cod_regiao, rs_dest.nome AS nome, rs_dest.latitude AS latitude, rs_dest.longitude AS longitude
, collect([c_ori.populacao,f.fluxo_geral,f.fluxo_aereo, f.fluxo_rodo]) AS cl, rs_pop AS rs_pop
WITH cod_regiao AS cod_regiao, nome AS nome,latitude AS latitude, longitude AS longitude, 
reduce(res = [0,0,0] , array IN cl | [res[0] + (array[0]*array[1]), res[1] + (array[0]*array[2]), res[2] + (array[0]*array[3])]) AS res, rs_pop AS rs_pop
RETURN cod_regiao, nome, latitude, longitude, res[0]/rs_pop AS fluxo_geral, res[1]/rs_pop AS fluxo_aereo, res[2]/rs_pop AS fluxo_rodo



//Exportar nodes
MATCH (c:Cidade)
WITH collect(c) AS cidades
CALL apoc.export.csv.data(cidades, [], "cidades.csv", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data

//Get top %
WITH 1 as per
MATCH(:Cidade)
WITH toInteger(floor(count(*) * per / 100)) AS lim
call apoc.cypher.run(
'MATCH (c:Cidade)
RETURN c.cod_mun 
order by c.total_pais DESC limit $limit'
, {limit : lim}) yield value
RETURN value AS cod_mun



//Algoritmos de caminho

//Find K-shortest paths
CALL gds.graph.project(
    'myGraph',
    'Cidade',
    'FLUXO_TRANSPORTE',
    {
        relationshipProperties: 'fluxo_invertido'
    }
)


MATCH (source:Cidade {cod_mun: 1200203}), (target:Cidade {cod_mun: 4204202})
CALL gds.shortestPath.yens.stream('myGraph', {
    sourceNode: source,
    targetNode: target,
    k: 3,
    relationshipWeightProperty: 'fluxo_invertido'
})
YIELD index, sourceNode, targetNode, totalCost, nodeIds, costs, path
RETURN
    index,
    gds.util.asNode(sourceNode).nome AS sourceNodeName,
    gds.util.asNode(targetNode).nome AS targetNodeName,
    totalCost,
    [nodeId IN nodeIds | gds.util.asNode(nodeId).nome] AS nodeNames,
    costs,
    nodes(path) as path
ORDER BY totalCost 


//Find shortes path to a list of pairs

//Algoritmo nao utiliza peso+
MATCH (c:Cidade{cod_mun:2611309}),(c_spreader:Cidade)-[r]->(h:Hierarquia) WHERE h.hierarquia = "1C"
WITH collect(c) AS node_source, collect(c_spreader) AS nodes
UNWIND nodes AS list_spreaders
UNWIND node_source AS c
WITH c,list_spreaders
WHERE c <> list_spreaders
MATCH p = allShortestPaths((c)-[*]->(list_spreaders))
RETURN p["start"]


CALL gds.graph.project(
    'myGraph',
    'Cidade',
    'FLUXO_TRANSPORTE',
    {
        relationshipProperties: 'fluxo_invertido'
    }
)
CALL gds.graph.project(
    'myGraph',
    'Cidade',
    'FLUXO_TRANSPORTE',
    {
        relationshipProperties: 'fluxo_geral'
    }
)

//Delta - primeiro faz para todos os nós e depois filtra
MATCH (source:Cidade {cod_mun: 2611309})
CALL gds.allShortestPaths.delta.stream('myGraph', {
    sourceNode: source,
    relationshipWeightProperty: 'fluxo_invertido',
    delta: 3.0
})
YIELD index, sourceNode, targetNode, totalCost, nodeIds, costs, path
WITH sourceNode AS source, targetNode AS target, nodeIds, path
MATCH (c_spreader:Cidade)-[r]->(h:Hierarquia) WHERE h.hierarquia = "1C"
AND gds.util.asNode(target).cod_mun = c_spreader.cod_mun
RETURN
    gds.util.asNode(source).nome AS sourceNodeName,
    gds.util.asNode(target).nome AS targetNodeName,
    [nodeId IN nodeIds | gds.util.asNode(nodeId).nome] AS nodeNames,
    nodes(path) as path

//Dijkstra
MATCH (c_spreader:Cidade)-[r]->(h:Hierarquia) WHERE h.hierarquia = "1C"
WITH collect(c_spreader) AS nodes
UNWIND nodes AS ct
MATCH (source:Cidade {cod_mun: 1200203}), (target:Cidade {cod_mun: ct.cod_mun})
CALL gds.shortestPath.dijkstra.stream('myGraph', {
    sourceNode: source,
    targetNode: target,
    relationshipWeightProperty: 'fluxo_geral'})
YIELD index, sourceNode, targetNode, totalCost, nodeIds, costs, path
RETURN
    index,
    gds.util.asNode(sourceNode).nome AS sourceNodeName,
    gds.util.asNode(targetNode).nome AS targetNodeName,
    totalCost,
    [nodeId IN nodeIds | gds.util.asNode(nodeId).nome] AS nodeNames,
    costs,
    nodes(path) as path
ORDER BY totalCost ASC

WITH 1 as per
MATCH(:Cidade)
WITH toInteger(floor(count(*) * per / 100)) AS lim
call apoc.cypher.run(
'MATCH (c:Cidade)
RETURN c
order by c.total_pais DESC limit $limit'
, {limit : lim}) yield value
RETURN value 

MATCH (c_spreader:Cidade)-[r]->(h:Hierarquia) WHERE h.hierarquia = "1C"


WITH 1 as per
MATCH(:Cidade)
WITH toInteger(floor(count(*) * per / 100)) AS lim
call apoc.cypher.run(
'MATCH (c:Cidade)
RETURN c.cod_mun
order by c.total_pais DESC limit $limit'
, {limit : lim}) YIELD value
WITH collect(value["c.cod_mun"]) AS codigos
UNWIND codigos AS ct
MATCH (source:Cidade {cod_mun: 1200203}), (target:Cidade {cod_mun: ct})
CALL gds.shortestPath.dijkstra.stream('myGraph', {
    sourceNode: source,
    targetNode: target,
    relationshipWeightProperty: 'fluxo_geral'})
YIELD index, sourceNode, targetNode, totalCost, nodeIds, costs, path
RETURN
    index,
    gds.util.asNode(sourceNode).nome AS sourceNodeName,
    gds.util.asNode(targetNode).nome AS targetNodeName,
    totalCost,
    [nodeId IN nodeIds | gds.util.asNode(nodeId).nome] AS nodeNames,
    costs,
    nodes(path) as path
ORDER BY totalCost ASC

WITH 1 as per
MATCH(:Cidade)
WITH toInteger(floor(count(*) * per / 100)) AS lim
call apoc.cypher.run(
'MATCH (c:Cidade)
RETURN c.cod_mun
order by c.total_pais DESC limit $limit'
, {limit : lim}) YIELD value
return  collect(value["c.cod_mun"]) AS nodes


WITH 1 as per
MATCH(:Cidade)
WITH toInteger(floor(count(*) * per / 100)) AS lim
MATCH (c:Cidade)
RETURN c limit toInteger(floor(count(c) * .1))
, {limit : lim}) YIELD value
WITH value.cod_mun AS cod
return  collect(cod) AS nodes